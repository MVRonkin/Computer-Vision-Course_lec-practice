{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5309a245-5bd4-47ba-ac48-7af17ee3e153",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'setup_torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accuracy, Precision, Recall, F1Score\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msetup_torch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     10\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     11\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     12\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m     13\u001b[0m ])\n\u001b[0;32m     15\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'setup_torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import pandas as pd\n",
    "from setup_torch import *\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Для CPU уменьшим batch_size; для GPU можно увеличить\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, )\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, )\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Модель\n",
    "# ----------------------------\n",
    "model = torchvision.models.resnet18(weights=None, num_classes=10)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Устройство\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Метрики (из torchmetrics)\n",
    "# ----------------------------\n",
    "num_classes = 10\n",
    "task = 'multiclass'\n",
    "\n",
    "metrics = {\n",
    "    'acc': Accuracy(task=task, num_classes=num_classes).to(device),\n",
    "    'prec': Precision(task=task, num_classes=num_classes, average='macro').to(device),\n",
    "    'rec': Recall(task=task, num_classes=num_classes, average='macro').to(device),\n",
    "    'f1': F1Score(task=task, num_classes=num_classes, average='macro').to(device),\n",
    "}\n",
    "\n",
    "# torchmetrics возвращает tensor → оборачиваем в лямбду для совместимости\n",
    "def make_metric_fn(metric_obj):\n",
    "    return lambda preds, target: metric_obj(preds, target)\n",
    "\n",
    "wrapped_metrics = {name: make_metric_fn(metric) for name, metric in metrics.items()}\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Оптимизатор и критерий\n",
    "# ----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Эффективный batch_size = 64 (без аккумуляции)\n",
    "# Если хотите эмулировать batch_size=256 → accumulation_steps=4 и lr *= 4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)  # базовый LR\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Запуск обучения\n",
    "# ----------------------------\n",
    "history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    metrics=wrapped_metrics,\n",
    "    epochs=20,\n",
    "    scheduler=scheduler,\n",
    "    patience=7,\n",
    "    min_delta=0.001,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=(device.type == 'cuda'),      # AMP только на GPU\n",
    "    ema_decay=0.999,\n",
    "    device=device,\n",
    "    checkpoint_path='best_model_checkpoint.pt',\n",
    "    verbose=True,\n",
    "    monitor_metric='f1',                  # early stopping по F1\n",
    "    mode='max',\n",
    "    accumulation_steps=1,                 # без аккумуляции (можно поставить 2, 4 и т.д.)\n",
    "    is_distributed=False                  # один GPU или CPU\n",
    ")\n",
    "\n",
    "print(\"\\n Обучение завершено!\")\n",
    "print(f\"Лучшая эпоха: {history.attrs['best_epoch'] + 1}\")\n",
    "print(f\"Лучший F1: {history.attrs['best_valid_score']:.4f}\")\n",
    "\n",
    "# Сохранить историю\n",
    "history.to_csv('training_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce42804-7e0e-4d39-a1c5-94c775c26649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dca147-0285-44a8-af91-849b37ef2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d7dd9a-9434-4861-86ab-5e8b227f574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_trainer_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ed92cb-c234-4961-9431-c59cc950aac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Device: cuda | Seed: 42 | TF32: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586a8cd6434e48fcade6bf6a11a03cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4354205f246b40df87e7c7c58b4f1b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 19.8s | LR: 3.00e-04 | Throughput: 2528 samples/s | Train Loss: 1.4298 | Val Loss: 2.3937 | Val f1: 0.0406 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e8b0a341824b69b41ed147a5406afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Async checkpoint saved to best_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d0690077234244bfb560b2306c107a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Time: 20.6s | LR: 3.00e-04 | Throughput: 2427 samples/s | Train Loss: 1.0081 | Val Loss: 2.3072 | Val f1: 0.0405 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9890514736e4366ae98fbea73737b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce4e7cf59d4b3495bb87f0fffb11f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Time: 20.9s | LR: 3.00e-04 | Throughput: 2392 samples/s | Train Loss: 0.8078 | Val Loss: 1.8973 | Val f1: 0.2157 ★\n",
      " Async checkpoint saved to best_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Настройка\n",
    "device = setup_experiment(seed=42, device_preference=\"auto\")\n",
    "\n",
    "# 2. Данные\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_ds = datasets.CIFAR10(\"data\", train=True, download=True, transform=transform)\n",
    "val_ds = datasets.CIFAR10(\"data\", train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "# 3. Модель\n",
    "model = torchvision.models.resnet18(weights=None, num_classes=10).to(device)\n",
    "# model = torch.compile(model, mode=\"reduce-overhead\")  # ← главный ускоритель!\n",
    "\n",
    "# 4. Метрики\n",
    "num_classes = 10\n",
    "metrics = {\n",
    "    \"acc\": Accuracy(task=\"multiclass\", num_classes=num_classes).to(device),\n",
    "    \"prec\": Precision(task=\"multiclass\", num_classes=num_classes, average=\"macro\").to(device),\n",
    "    \"rec\": Recall(task=\"multiclass\", num_classes=num_classes, average=\"macro\").to(device),\n",
    "    \"f1\": F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\").to(device),\n",
    "}\n",
    "\n",
    "# Оборачиваем для совместимости\n",
    "wrapped_metrics = {k: lambda pred, target, fn=fn: fn(pred, target) for k, fn in metrics.items()}\n",
    "\n",
    "# 5. Оптимизатор\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=3)\n",
    "\n",
    "\n",
    "# 6. Запуск\n",
    "history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler = scheduler,\n",
    "    criterion=torch.nn.CrossEntropyLoss().to(device),\n",
    "    metrics=wrapped_metrics,\n",
    "    device=device,\n",
    "    epochs=3,\n",
    "    patience=7,\n",
    "    monitor_metric=\"f1\",\n",
    "    mode=\"max\",\n",
    "    use_amp=(device.type == \"cuda\"),\n",
    "    ema_decay=0.999,\n",
    "    grad_clip=1.0,\n",
    "    accumulation_steps=1,\n",
    "    checkpoint_path=\"best_model.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a828efdf-adc1-4812-99a6-c1d2db96e30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ee237-7fc6-4793-a3b9-2d979b750a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
