{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5309a245-5bd4-47ba-ac48-7af17ee3e153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 96.9s | LR: 5.05e-04 | Train Loss: 2.0635 | Val Loss: 2.5068 | Val f1: 0.0451 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Time: 97.1s | LR: 9.76e-04 | Train Loss: 1.3671 | Val Loss: 2.4940 | Val f1: 0.0184 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Time: 88.4s | LR: 9.46e-04 | Train Loss: 1.0631 | Val Loss: 2.3471 | Val f1: 0.0184 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Time: 87.4s | LR: 9.05e-04 | Train Loss: 0.8340 | Val Loss: 2.4170 | Val f1: 0.0657 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Time: 85.7s | LR: 8.55e-04 | Train Loss: 0.6943 | Val Loss: 1.9593 | Val f1: 0.1776 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Time: 86.9s | LR: 7.96e-04 | Train Loss: 0.5685 | Val Loss: 1.7274 | Val f1: 0.3125 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Time: 85.6s | LR: 7.30e-04 | Train Loss: 0.4569 | Val Loss: 1.2723 | Val f1: 0.5228 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Time: 86.1s | LR: 6.58e-04 | Train Loss: 0.3483 | Val Loss: 1.0612 | Val f1: 0.6373 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Time: 104.1s | LR: 5.82e-04 | Train Loss: 0.2524 | Val Loss: 0.8729 | Val f1: 0.7067 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Time: 118.0s | LR: 5.05e-04 | Train Loss: 0.1728 | Val Loss: 0.8579 | Val f1: 0.7326 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Time: 87.2s | LR: 4.28e-04 | Train Loss: 0.1194 | Val Loss: 0.8762 | Val f1: 0.7528 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Time: 87.6s | LR: 3.52e-04 | Train Loss: 0.0761 | Val Loss: 0.8958 | Val f1: 0.7736 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Time: 87.2s | LR: 2.80e-04 | Train Loss: 0.0492 | Val Loss: 0.9976 | Val f1: 0.7746 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Time: 87.1s | LR: 2.14e-04 | Train Loss: 0.0280 | Val Loss: 1.1028 | Val f1: 0.7768 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Time: 87.7s | LR: 1.55e-04 | Train Loss: 0.0148 | Val Loss: 1.2010 | Val f1: 0.7740 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Time: 87.2s | LR: 1.05e-04 | Train Loss: 0.0062 | Val Loss: 1.3391 | Val f1: 0.7731 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Time: 87.2s | LR: 6.40e-05 | Train Loss: 0.0027 | Val Loss: 1.3958 | Val f1: 0.7756 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b67e9c282c3490a80492549e12898fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Time: 88.7s | LR: 3.42e-05 | Train Loss: 0.0011 | Val Loss: 1.4567 | Val f1: 0.7726 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095b5030bc51411e9ca819301a5ae93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 88\u001b[0m\n\u001b[1;32m     77\u001b[0m scheduler, _ \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mcreate_scheduler_v2(\n\u001b[1;32m     78\u001b[0m optimizer,\n\u001b[1;32m     79\u001b[0m     sched\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# 8. Запуск обучения\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m history, batch_hist \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# AMP только на GPU\u001b[39;49;00m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.999\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model_checkpoint.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# early stopping по F1\u001b[39;49;00m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# без аккумуляции (можно поставить 2, 4 и т.д.)\u001b[39;49;00m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_batch_history\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Обучение завершено!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛучшая эпоха: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Computer-Vision-Course_lec-practice/2025/WS/torch_trainer.py:343\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, metrics, epochs, scheduler, device, checkpoint_path, monitor_metric, mode, patience, min_delta, grad_clip, use_amp, ema_decay, accumulation_steps, verbose, return_batch_history, start_from_checkpoint)\u001b[0m\n\u001b[1;32m    340\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# --- Train ---\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m train_loss, train_metrics, train_batch_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_clip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulation_steps\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# --- Validate ---\u001b[39;00m\n\u001b[1;32m    350\u001b[0m val_loss, val_metrics, val_batch_history \u001b[38;5;241m=\u001b[39m evaluate_epoch(\n\u001b[1;32m    351\u001b[0m     model, val_loader, criterion, metrics, device, ema\u001b[38;5;241m=\u001b[39mema\n\u001b[1;32m    352\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Computer-Vision-Course_lec-practice/2025/WS/torch_trainer.py:140\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, criterion, metrics, device, use_amp, grad_clip, ema, accumulation_steps)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_amp:\n\u001b[1;32m    139\u001b[0m         scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m--> 140\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_amp:\n\u001b[1;32m    143\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:43\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:231\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m    226\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`parameters` is an empty generator, no gradient clipping will occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    229\u001b[0m         )\n\u001b[1;32m    230\u001b[0m grads \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 231\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m \u001b[43m_get_total_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_if_nonfinite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:43\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:103\u001b[0m, in \u001b[0;36m_get_total_norm\u001b[0;34m(tensors, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 103\u001b[0m             [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m device_tensors]\n\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    106\u001b[0m total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\n\u001b[1;32m    107\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack([norm\u001b[38;5;241m.\u001b[39mto(first_device) \u001b[38;5;28;01mfor\u001b[39;00m norm \u001b[38;5;129;01min\u001b[39;00m norms]), norm_type\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import pandas as pd\n",
    "from torch_trainer import *\n",
    "from timm import optim, scheduler\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Для CPU уменьшим batch_size; для GPU можно увеличить\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, )\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, )\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Модель\n",
    "# ----------------------------\n",
    "model = torchvision.models.resnet18(weights=None, num_classes=10)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Устройство\n",
    "# ----------------------------\n",
    "device = (\n",
    "    torch.device('cuda') if torch.cuda.is_available()\n",
    "    else torch.device('mps') if torch.backends.mps.is_available()\n",
    "    else torch.device('cpu')\n",
    ")\n",
    "print(f'Using device: {device}')\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Метрики (из torchmetrics)\n",
    "# ----------------------------\n",
    "num_classes = 10\n",
    "task = 'multiclass'\n",
    "\n",
    "metrics = {\n",
    "    'acc': Accuracy(task=task, num_classes=num_classes).to(device),\n",
    "    'prec': Precision(task=task, num_classes=num_classes, average='macro').to(device),\n",
    "    'rec': Recall(task=task, num_classes=num_classes, average='macro').to(device),\n",
    "    'f1': F1Score(task=task, num_classes=num_classes, average='macro').to(device),\n",
    "}\n",
    "\n",
    "# torchmetrics возвращает tensor → оборачиваем в лямбду для совместимости\n",
    "def make_metric_fn(metric_obj):\n",
    "    return lambda preds, target: metric_obj(preds, target)\n",
    "\n",
    "wrapped_metrics = {name: make_metric_fn(metric) for name, metric in metrics.items()}\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Оптимизатор и критерий\n",
    "# ----------------------------\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Эффективный batch_size = 128 (без аккумуляции)\n",
    "# Если хотите эмулировать batch_size=512 → accumulation_steps=4 и lr *= 4\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)  # базовый LR\n",
    "\n",
    "# # Scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "optimizer = timm.optim.create_optimizer_v2(\n",
    "    model,\n",
    "    opt='adamw',\n",
    "    lr=3e-4,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "scheduler, _ = timm.scheduler.create_scheduler_v2(\n",
    "optimizer,\n",
    "    sched='cosine',\n",
    "    num_epochs=20,\n",
    "    warmup_epochs=2,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Запуск обучения\n",
    "# ----------------------------\n",
    "history, batch_hist = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    metrics=wrapped_metrics,\n",
    "    epochs=20,\n",
    "    scheduler=scheduler,\n",
    "    patience=7,\n",
    "    min_delta=0.001,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=(device.type == 'cuda'),      # AMP только на GPU\n",
    "    ema_decay=0.999,\n",
    "    device=device,\n",
    "    checkpoint_path='best_model_checkpoint.pt',\n",
    "    verbose=True,\n",
    "    monitor_metric='f1',                  # early stopping по F1\n",
    "    mode='max',\n",
    "    accumulation_steps=1,                 # без аккумуляции (можно поставить 2, 4 и т.д.)\n",
    "    return_batch_history = True,\n",
    ")\n",
    "\n",
    "print(\"\\n Обучение завершено!\")\n",
    "print(f\"Лучшая эпоха: {history.attrs['best_epoch'] + 1}\")\n",
    "print(f\"Лучший F1: {history.attrs['best_score']:.4f}\")\n",
    "\n",
    "# Сохранить историю\n",
    "history.to_csv('training_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea1cd89-ff8b-45c2-b474-97f72bdbd297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch_hist\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_hist' is not defined"
     ]
    }
   ],
   "source": [
    "batch_hist['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fce42804-7e0e-4d39-a1c5-94c775c26649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f6418e-c058-4eea-a582-4fdbdf01b1b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_batch_history(\u001b[43mbatch_hist\u001b[49m, metric_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_hist' is not defined"
     ]
    }
   ],
   "source": [
    "plot_batch_history(batch_hist, metric_name='acc', window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082c075-c9b0-4450-9c7e-df014da943bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e0cf0-7408-4c6a-81db-0418c4c9c2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d7dd9a-9434-4861-86ab-5e8b227f574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_trainer_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ed92cb-c234-4961-9431-c59cc950aac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Device: cuda | Seed: 42 | TF32: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586a8cd6434e48fcade6bf6a11a03cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4354205f246b40df87e7c7c58b4f1b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 19.8s | LR: 3.00e-04 | Throughput: 2528 samples/s | Train Loss: 1.4298 | Val Loss: 2.3937 | Val f1: 0.0406 ★\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e8b0a341824b69b41ed147a5406afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Async checkpoint saved to best_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d0690077234244bfb560b2306c107a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Time: 20.6s | LR: 3.00e-04 | Throughput: 2427 samples/s | Train Loss: 1.0081 | Val Loss: 2.3072 | Val f1: 0.0405 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9890514736e4366ae98fbea73737b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce4e7cf59d4b3495bb87f0fffb11f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Time: 20.9s | LR: 3.00e-04 | Throughput: 2392 samples/s | Train Loss: 0.8078 | Val Loss: 1.8973 | Val f1: 0.2157 ★\n",
      " Async checkpoint saved to best_model.pt\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a828efdf-adc1-4812-99a6-c1d2db96e30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "018ee237-7fc6-4793-a3b9-2d979b750a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Используем встроенные функции SMP\n",
    "class SMPCombinedLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.dice_loss = smp.losses.DiceLoss(mode='binary')\n",
    "        self.bce_loss = smp.losses.SoftBCEWithLogitsLoss(smooth_factor=0.0)\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # Убедимся, что target имеет правильную размерность\n",
    "        if target.dim() == 3:\n",
    "            target = target.unsqueeze(1)  # Добавляем размерность канала\n",
    "        target = target.float()\n",
    "        \n",
    "        dice = self.dice_loss(pred, target)\n",
    "        bce = self.bce_loss(pred, target)\n",
    "        return self.dice_weight * dice +  (1-self.dice_weight) * bce\n",
    "\n",
    "\n",
    "\n",
    "# Метрики из SMP\n",
    "def iou_score(pred, target):\n",
    "    if target.dim() == 3:\n",
    "        target = target.unsqueeze(1)  # Добавляем размерность канала\n",
    "    # Преобразуем в бинарные предсказания\n",
    "    pred_bin = (torch.sigmoid(pred) > 0.5).float()\n",
    "    target = target.float()\n",
    "    \n",
    "    intersection = (pred_bin * target).sum((1, 2, 3))\n",
    "    union = (pred_bin + target - pred_bin * target).sum((1, 2, 3))\n",
    "    \n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.mean()\n",
    "\n",
    "def f_score(pred, target):\n",
    "    if target.dim() == 3:\n",
    "        target = target.unsqueeze(1)  # Добавляем размерность канала\n",
    "    # Преобразуем в бинарные предсказания\n",
    "    pred_bin = (torch.sigmoid(pred) > 0.5).float()\n",
    "    target = target.float()\n",
    "    \n",
    "    intersection = (pred_bin * target).sum((1, 2, 3))\n",
    "    total_pred = pred_bin.sum((1, 2, 3))\n",
    "    total_target = target.sum((1, 2, 3))\n",
    "    \n",
    "    f1 = (2 * intersection + 1e-6) / (total_pred + total_target + 1e-6)\n",
    "    return f1.mean()\n",
    "\n",
    "def accuracy_score(pred, target):\n",
    "    if target.dim() == 3:\n",
    "        target = target.unsqueeze(1)  # Добавляем размерность канала\n",
    "    # Преобразуем в бинарные предсказания\n",
    "    pred_bin = (torch.sigmoid(pred) > 0.5).float()\n",
    "    target = target.float()\n",
    "    \n",
    "    correct = (pred_bin == target).float().sum((1, 2, 3))\n",
    "    total = target.new_tensor(target.shape[1] * target.shape[2] * target.shape[3])\n",
    "    \n",
    "    acc = (correct + 1e-6) / (total + 1e-6)\n",
    "    return acc.mean()\n",
    "\n",
    "# Определим метрики\n",
    "metrics = {\n",
    "    'iou': iou_score,\n",
    "    'f1': f_score,\n",
    "    'acc': accuracy_score\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d120c86-05da-47ea-beba-0cb04382251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "criterion = SMPCombinedLoss(dice_weight=0.5)\n",
    "criterion.to(device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)  # базовый LR\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3015aa-8097-46a9-9f34-fe500fa112cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d061d5382ac645d987682b44338001d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50202a2b27bb4c249ff3f27b9453254b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 22.9s | LR: 1.00e-03 | Train Loss: 0.0927 | Val Loss: 0.0998 | Val iou: 0.8744 ★\n"
     ]
    }
   ],
   "source": [
    "# Запускаем обучение\n",
    "history_df, batch_history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    metrics=metrics,\n",
    "    epochs=1,\n",
    "    scheduler = scheduler,\n",
    "    device=device,\n",
    "    checkpoint_path=\"best_segmentation_model.pt\",\n",
    "    monitor_metric=\"iou\",\n",
    "    mode=\"max\",\n",
    "    patience=10,\n",
    "    min_delta=1e-4,\n",
    "    grad_clip=1.0,\n",
    "    use_amp=(device.type == 'cuda'),\n",
    "    accumulation_steps=1,\n",
    "    verbose=True,\n",
    "    return_batch_history = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8acd8cb9-3304-483b-ae05-76e7fdee9f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 31,043,521\n",
      "Input shape: torch.Size([1, 3, 256, 256])\n",
      "Output shape: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNetBlock(nn.Module):\n",
    "    \"\"\"Блок U-Net с двумя свертками и активацией\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"Упрощенная архитектура U-Net\"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        in_ch = in_channels\n",
    "        for feature in features:\n",
    "            self.encoder.append(UNetBlock(in_ch, feature))\n",
    "            in_ch = feature\n",
    "            \n",
    "        # Bottleneck\n",
    "        self.bottleneck = UNetBlock(features[-1], features[-1]*2)\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        in_ch = features[-1]*2  # channels after bottleneck\n",
    "        for feature in reversed(features):\n",
    "            self.decoder.append(\n",
    "                nn.ConvTranspose2d(in_ch, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            # После конкатенации: feature*2 (из skip connection + upsampled)\n",
    "            self.decoder.append(UNetBlock(feature*2, feature))\n",
    "            in_ch = feature\n",
    "            \n",
    "        # Output layer\n",
    "        self.output = nn.Conv2d(features[0], out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # Encoder\n",
    "        for block in self.encoder:\n",
    "            x = block(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "            \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Decoder\n",
    "        skip_connections = skip_connections[::-1]  # Reverse for decoder\n",
    "        \n",
    "        for i in range(0, len(self.decoder), 2):\n",
    "            x = self.decoder[i](x)  # ConvTranspose2d\n",
    "            skip = skip_connections[i//2]\n",
    "            \n",
    "            # Ensure same spatial dimensions\n",
    "            if x.shape[2:] != skip.shape[2:]:\n",
    "                # Interpolate to match spatial dimensions\n",
    "                x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=True)\n",
    "            \n",
    "            # Concatenate skip connection\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = self.decoder[i+1](x)  # UNetBlock\n",
    "            \n",
    "        return self.output(x)\n",
    "\n",
    "# Пример использования\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Проверка размеров\n",
    "x = torch.randn(1, 3, 256, 256)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03c19d58-e3eb-442e-ad36-015c37acda83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 1,026,401\n",
      "Input shape: torch.Size([1, 3, 256, 256])\n",
      "Output shape: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class TimmUNet(nn.Module):\n",
    "    \"\"\"U-Net с использованием backbone из timm\"\"\"\n",
    "    def __init__(self, \n",
    "                 backbone_name='mobilenetv3_small_100',  # легкий backbone\n",
    "                 in_channels=3, \n",
    "                 out_channels=1,\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Загружаем предобученную модель\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name, \n",
    "            features_only=True, \n",
    "            pretrained=pretrained,\n",
    "            out_indices=(0, 1, 2, 3)  # выбираем разные уровни\n",
    "        )\n",
    "        \n",
    "        # Получаем количество каналов для каждого уровня\n",
    "        self.feature_channels = self.backbone.feature_info.channels()\n",
    "        \n",
    "        # Уменьшаем количество каналов для легкости\n",
    "        self.reduce_convs = nn.ModuleList()\n",
    "        for ch in self.feature_channels:\n",
    "            self.reduce_convs.append(\n",
    "                nn.Conv2d(ch, 32, 1)  # уменьшаем до 32 каналов\n",
    "            )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        \n",
    "        # Для каждого уровня decoder создаем upsampling + conv\n",
    "        for i in range(len(self.feature_channels) - 1):\n",
    "            self.decoder_blocks.append(\n",
    "                nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)  # upsampling\n",
    "            )\n",
    "            # После конкатенации: 32 (upsampled) + 32 (skip) = 64\n",
    "            self.decoder_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(64, 32, 3, padding=1),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, 3, padding=1),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Дополнительный upsampling до исходного размера\n",
    "        # Если после decoder все еще меньше чем вход, добавляем еще upsampling\n",
    "        self.final_upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.output = nn.Conv2d(32, out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Получаем признаки из backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Уменьшаем количество каналов\n",
    "        reduced_features = []\n",
    "        for feat, conv in zip(features, self.reduce_convs):\n",
    "            reduced_features.append(conv(feat))\n",
    "        \n",
    "        # Начинаем с самого глубокого уровня\n",
    "        x = reduced_features[-1]\n",
    "        \n",
    "        # Decoder с skip connections\n",
    "        for i in range(0, len(self.decoder_blocks), 2):\n",
    "            # Upsampling\n",
    "            x = self.decoder_blocks[i](x)\n",
    "            \n",
    "            # Добавляем skip connection\n",
    "            skip_idx = len(reduced_features) - 2 - (i // 2)\n",
    "            if skip_idx >= 0:\n",
    "                skip = reduced_features[skip_idx]\n",
    "                \n",
    "                # Убедимся, что размеры совпадают\n",
    "                if x.shape[2:] != skip.shape[2:]:\n",
    "                    x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=True)\n",
    "                \n",
    "                x = torch.cat([x, skip], dim=1)\n",
    "            \n",
    "            # Convolution block\n",
    "            x = self.decoder_blocks[i+1](x)\n",
    "        \n",
    "        # Дополнительный upsampling до размера входа, если нужно\n",
    "        if x.shape[2:] != features[0].shape[2:]:\n",
    "            x = self.final_upsample(x)\n",
    "        \n",
    "        # Убедимся, что размер совпадает с входом\n",
    "        if x.shape[2:] != torch.Size([256, 256]):\n",
    "            x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return self.output(x)\n",
    "\n",
    "# Пример использования\n",
    "model = TimmUNet(\n",
    "    backbone_name='mobilenetv3_small_100',  # очень легкий backbone\n",
    "    in_channels=3, \n",
    "    out_channels=1,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Проверка размеров\n",
    "x = torch.randn(1, 3, 256, 256)\n",
    "with torch.no_grad():\n",
    "    y = model(x)\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed98e8c-41fd-4fe6-b529-2087e122499f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
